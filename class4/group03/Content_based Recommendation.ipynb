{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([i for i in range(100)])\n",
    "b = np.array([(i*2 +5)*3 for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "    denominator = np.dot(A,B)\n",
    "    nummeraotor = math.sqrt((A.T@A * B.T@B))    \n",
    "    return denominator/nummeraotor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997757815947825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top n approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_euclidean(train_matrix, test_matrix, k):\n",
    "    neightbor = {}\n",
    "    for i in range(len(test_matrix)):\n",
    "        dist = np.linalg.norm((train_matrix - test_matrix[i].T), axis= 1)\n",
    "        topk = np.argsort(dist)[:k]\n",
    "        neightbor[i] = topk\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cosine(train_matrix, test_matrix, k):\n",
    "    neightbor = {}\n",
    "    norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "    norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "    for i in range(len(test_matrix)):\n",
    "        cos = (train_matrix @ test_matrix[i].T) / (norm_train * norm_test[i])\n",
    "        topk = np.argsort(-cos)[:k]\n",
    "        neightbor[i] = topk\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cosine_brute(train_matrix, test_matrix, k):\n",
    "    neightbor = {}\n",
    "    for i in range(len(test_matrix)):\n",
    "        cos = np.array([(cos_sim(test_matrix[i], j)) for j in train_matrix])\n",
    "        topk = np.argsort(-cos)[:k]\n",
    "        neightbor[i] = topk\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson_correlation(train_matrix, test_matrix, k):\n",
    "    train_matrix = train_matrix-np.mean(train_matrix, axis = 1).reshape(-1,1)\n",
    "    test_matrix = test_matrix-np.mean(test_matrix, axis = 1).reshape(-1,1)\n",
    "    neightbor = {}\n",
    "    norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "    norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "    for i in range(len(test_matrix)):\n",
    "        denominator = train_matrix @ test_matrix[i].T\n",
    "        numerator = norm_train * norm_test[i]\n",
    "        cos = denominator / numerator\n",
    "        topk = np.argsort(-cos)[:k]\n",
    "        neightbor[i] = topk\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.random.multivariate_normal(np.zeros(100), np.identity(100), 1000)\n",
    "k = 5\n",
    "test_matrix = np.random.multivariate_normal(np.zeros(100), np.identity(100), 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([289, 211, 756, 212, 825]),\n",
       " 1: array([356, 176, 864, 260, 760]),\n",
       " 2: array([866, 355,  97, 425, 622]),\n",
       " 3: array([ 87, 988, 895, 914, 439]),\n",
       " 4: array([212, 801, 414, 368, 927]),\n",
       " 5: array([818, 926, 381, 778, 891]),\n",
       " 6: array([109, 499, 866, 423, 490]),\n",
       " 7: array([264, 245, 960, 604, 734]),\n",
       " 8: array([930, 959,  25, 914, 439]),\n",
       " 9: array([140, 880, 813, 563, 190]),\n",
       " 10: array([174, 880,  95, 909, 323]),\n",
       " 11: array([323, 700, 658, 879, 959]),\n",
       " 12: array([666, 904, 176, 604, 893]),\n",
       " 13: array([  7, 384, 666,  49, 223]),\n",
       " 14: array([ 87, 960,  61, 260, 633]),\n",
       " 15: array([890, 360, 145, 690, 520]),\n",
       " 16: array([433, 498, 325, 801, 746]),\n",
       " 17: array([445, 116, 604, 772, 697]),\n",
       " 18: array([188, 644, 220, 605, 793]),\n",
       " 19: array([483, 363, 473, 230, 100])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_euclidean(matrix, test_matrix, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[289, 211, 756, 212, 825],\n",
       "       [356, 176, 864, 260, 760],\n",
       "       [866, 355,  97, 425, 622],\n",
       "       [ 87, 988, 895, 914, 439],\n",
       "       [212, 801, 414, 368, 927],\n",
       "       [818, 926, 381, 778, 891],\n",
       "       [109, 499, 866, 423, 490],\n",
       "       [264, 245, 960, 604, 734],\n",
       "       [930, 959,  25, 914, 439],\n",
       "       [140, 880, 813, 563, 190],\n",
       "       [174, 880,  95, 909, 323],\n",
       "       [323, 700, 658, 879, 959],\n",
       "       [666, 904, 176, 604, 893],\n",
       "       [  7, 384, 666,  49, 223],\n",
       "       [ 87, 960,  61, 260, 633],\n",
       "       [890, 360, 145, 690, 520],\n",
       "       [433, 498, 325, 801, 746],\n",
       "       [445, 116, 604, 772, 697],\n",
       "       [188, 644, 220, 605, 793],\n",
       "       [483, 363, 473, 230, 100]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NearestNeighbors(n_neighbors= 5, metric='minkowski', algorithm='brute')\n",
    "model.fit(matrix)\n",
    "model.kneighbors(test_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[211, 615, 678, 194,  80],\n",
       "       [864, 356, 340, 608, 686],\n",
       "       [ 97, 474, 251, 544, 839],\n",
       "       [988,  87, 439, 516, 895],\n",
       "       [212,  42, 927, 595, 948],\n",
       "       [341, 926, 741, 778, 853],\n",
       "       [109,  26, 180, 317, 544],\n",
       "       [264, 734, 204, 860, 245],\n",
       "       [ 25, 439, 244, 243, 930],\n",
       "       [140,  14, 813, 563, 880],\n",
       "       [798, 970, 174, 180, 909],\n",
       "       [879, 323, 878, 700, 647],\n",
       "       [116, 904, 612, 221, 587],\n",
       "       [645, 558, 526,   7, 270],\n",
       "       [ 87, 956, 960,  61, 991],\n",
       "       [890, 690,  90, 686, 864],\n",
       "       [498, 746, 325, 401, 509],\n",
       "       [116, 755, 445, 134, 182],\n",
       "       [188, 951, 605, 995, 793],\n",
       "       [483, 230, 236, 296, 761]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NearestNeighbors(n_neighbors= 5, metric='cosine', algorithm='brute')\n",
    "model.fit(matrix)\n",
    "model.kneighbors(test_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([211, 615, 678, 194,  80]),\n",
       " 1: array([864, 356, 340, 608, 686]),\n",
       " 2: array([ 97, 474, 251, 544, 839]),\n",
       " 3: array([988,  87, 439, 516, 895]),\n",
       " 4: array([212,  42, 927, 595, 948]),\n",
       " 5: array([341, 926, 741, 778, 853]),\n",
       " 6: array([109,  26, 180, 317, 544]),\n",
       " 7: array([264, 734, 204, 860, 245]),\n",
       " 8: array([ 25, 439, 244, 243, 930]),\n",
       " 9: array([140,  14, 813, 563, 880]),\n",
       " 10: array([798, 970, 174, 180, 909]),\n",
       " 11: array([879, 323, 878, 700, 647]),\n",
       " 12: array([116, 904, 612, 221, 587]),\n",
       " 13: array([645, 558, 526,   7, 270]),\n",
       " 14: array([ 87, 956, 960,  61, 991]),\n",
       " 15: array([890, 690,  90, 686, 864]),\n",
       " 16: array([498, 746, 325, 401, 509]),\n",
       " 17: array([116, 755, 445, 134, 182]),\n",
       " 18: array([188, 951, 605, 995, 793]),\n",
       " 19: array([483, 230, 236, 296, 761])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cosine(matrix, test_matrix, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([211, 615, 194, 678,  80]),\n",
       " 1: array([864, 356, 608, 340, 686]),\n",
       " 2: array([ 97, 474, 251, 544, 839]),\n",
       " 3: array([988,  87, 439, 516, 427]),\n",
       " 4: array([ 42, 212, 368, 414, 948]),\n",
       " 5: array([341, 926, 741, 778, 853]),\n",
       " 6: array([109,  26, 180, 317, 544]),\n",
       " 7: array([264, 734, 245, 204, 458]),\n",
       " 8: array([439,  25, 244, 243, 930]),\n",
       " 9: array([140,  14, 813, 563, 880]),\n",
       " 10: array([174, 798, 970, 180, 909]),\n",
       " 11: array([878, 323, 700, 879, 655]),\n",
       " 12: array([116, 904, 612, 587, 221]),\n",
       " 13: array([645, 558, 526, 270, 384]),\n",
       " 14: array([ 87,  61, 960, 956, 780]),\n",
       " 15: array([890, 690,  90, 686, 864]),\n",
       " 16: array([498, 325, 746, 401, 298]),\n",
       " 17: array([116, 755, 445, 182, 134]),\n",
       " 18: array([188, 951, 605, 995, 793]),\n",
       " 19: array([483, 230, 390, 761, 236])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pearson_correlation(matrix, test_matrix, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson correlation metric is very similar to that of cosine distance. \n",
    "    - From the formular, Pearson correlation can be seen as the centralized cosine distance.\n",
    "    \n",
    "    \n",
    "- Most of them are the same, except ```number 9```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002360222694141913"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(test_matrix[0], matrix[674])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cosine2(train_matrix, test_matrix, k):\n",
    "    neightbor = {}\n",
    "    norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "    norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "    for i in range(len(test_matrix)):\n",
    "        cos = (train_matrix @ test_matrix[i].T) / (norm_train * norm_test[i])\n",
    "        topk = np.argsort(-cos)[:k]\n",
    "        top_cos = -np.sort(-cos)[:k]\n",
    "        neightbor[i] = [topk,top_cos]\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_euclidean2(train_matrix, test_matrix, k):\n",
    "    neightbor = {}\n",
    "    for i in range(len(test_matrix)):\n",
    "        dist = np.linalg.norm((train_matrix - test_matrix[i].T), axis= 1)\n",
    "        topk = np.argsort(dist)[:k]\n",
    "        top_dist = -np.sort(-dist)[:k]\n",
    "        neightbor[i] = [topk,top_dist]\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson_correlation2(train_matrix, test_matrix, k):\n",
    "    train_matrix = train_matrix-np.mean(train_matrix, axis = 1).reshape(-1,1)\n",
    "    test_matrix = test_matrix-np.mean(test_matrix, axis = 1).reshape(-1,1)\n",
    "    neightbor = {}\n",
    "    norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "    norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "    for i in range(len(test_matrix)):\n",
    "        denominator = train_matrix @ test_matrix[i].T\n",
    "        numerator = norm_train * norm_test[i]\n",
    "        cos = denominator / numerator\n",
    "        topk = np.argsort(-cos)[:k]\n",
    "        top_cos = -np.sort(-cos)[:k]\n",
    "        neightbor[i] = [topk,top_cos]\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([211, 615, 678, 194,  80]),\n",
       "  array([0.3290458 , 0.31835469, 0.27511283, 0.2701224 , 0.26696161])],\n",
       " 1: [array([864, 356, 340, 608, 686]),\n",
       "  array([0.34493494, 0.31901962, 0.27357732, 0.27001744, 0.26250222])],\n",
       " 2: [array([ 97, 474, 251, 544, 839]),\n",
       "  array([0.30731037, 0.30363464, 0.29079658, 0.28586647, 0.27020143])],\n",
       " 3: [array([988,  87, 439, 516, 895]),\n",
       "  array([0.35450679, 0.30967128, 0.29468035, 0.26854118, 0.24887457])],\n",
       " 4: [array([212,  42, 927, 595, 948]),\n",
       "  array([0.27965181, 0.26464766, 0.25462251, 0.23897476, 0.22954045])],\n",
       " 5: [array([341, 926, 741, 778, 853]),\n",
       "  array([0.33118382, 0.32734647, 0.29761022, 0.29248301, 0.28852   ])],\n",
       " 6: [array([109,  26, 180, 317, 544]),\n",
       "  array([0.32264976, 0.28058366, 0.26616889, 0.25802081, 0.2539791 ])],\n",
       " 7: [array([264, 734, 204, 860, 245]),\n",
       "  array([0.27161011, 0.26355885, 0.23767118, 0.23754133, 0.23315771])],\n",
       " 8: [array([ 25, 439, 244, 243, 930]),\n",
       "  array([0.32640418, 0.3099177 , 0.29510517, 0.27574833, 0.26468136])],\n",
       " 9: [array([140,  14, 813, 563, 880]),\n",
       "  array([0.39947374, 0.30558472, 0.29562948, 0.28292675, 0.27670903])],\n",
       " 10: [array([798, 970, 174, 180, 909]),\n",
       "  array([0.35764086, 0.35379467, 0.34771443, 0.27057125, 0.268815  ])],\n",
       " 11: [array([879, 323, 878, 700, 647]),\n",
       "  array([0.28055541, 0.27953815, 0.27546393, 0.26925017, 0.26873235])],\n",
       " 12: [array([116, 904, 612, 221, 587]),\n",
       "  array([0.32919246, 0.29002613, 0.25900775, 0.25192995, 0.25100548])],\n",
       " 13: [array([645, 558, 526,   7, 270]),\n",
       "  array([0.31893517, 0.26691013, 0.25758684, 0.24480078, 0.24017821])],\n",
       " 14: [array([ 87, 956, 960,  61, 991]),\n",
       "  array([0.34067262, 0.29465281, 0.29024335, 0.28503625, 0.28061218])],\n",
       " 15: [array([890, 690,  90, 686, 864]),\n",
       "  array([0.27142821, 0.25864999, 0.256523  , 0.25445623, 0.25233395])],\n",
       " 16: [array([498, 746, 325, 401, 509]),\n",
       "  array([0.31461401, 0.3101969 , 0.30977317, 0.30220821, 0.28933802])],\n",
       " 17: [array([116, 755, 445, 134, 182]),\n",
       "  array([0.32819053, 0.29657342, 0.27057827, 0.26513597, 0.26436413])],\n",
       " 18: [array([188, 951, 605, 995, 793]),\n",
       "  array([0.31596588, 0.29047979, 0.28833305, 0.28586813, 0.27796054])],\n",
       " 19: [array([483, 230, 236, 296, 761]),\n",
       "  array([0.29776211, 0.28307161, 0.26550113, 0.26267817, 0.26039545])]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cosine2(matrix, test_matrix, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Users Simulation \n",
    "\n",
    "\n",
    "- The reason that we simulate the data is that by doing this, we have a better control of the missing proportion ```threshold```, and it might be a good experiment when dealing with \"Cold Start\" problem. \n",
    "\n",
    "\n",
    "- New Users might not have so many ratings as those in our database. (training data)\n",
    "\n",
    "\n",
    "### Data Generation Process\n",
    "\n",
    "- Use data generation process to simulate the data for new users and miss part.\n",
    "\n",
    "    - Assume each user has a stable preference of choosing rating or not rating. \n",
    "       \n",
    "    - Let $P$ be the event that the entry would be dropped from the artificial matrix.  Then given one user $i$ , the probability of rating or not rating is the same, that is $p_{i}$. \n",
    "    \n",
    "    - For each item of given user, it has probability $p_{i}$ to be dropped out from the matrix.    \n",
    "\n",
    "        - Generate each $p_{i} \\sim U(0, a)$, where $a < 1$, and $a$ is the ```threshold```.\n",
    "        \n",
    "        - The reason for setting up the threhold equals to 0.8 instead of 1 is that we don't wanna the $p_{i} = 1$ since otherwise our algorithm won't work.\n",
    "        \n",
    "        - Given each user, let $\\mathbb{1_{drop}}$ to be a indicator variable denotes whether to drop the rating on item $j$. $\\mathbb{1_{drop}} \\sim Bern (p_{i})$ \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is an example\n",
    "\n",
    "<hr style=\"height:0.5px;\">\n",
    "<br><br>\n",
    "<img src=\"Data_generalization.png\">\n",
    "<br><br>\n",
    "<hr style=\"height:0.5px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix2 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 40)\n",
    "train_matrix2 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(matrix, threshold):\n",
    "    '''\n",
    "    - matrix(np array of float): artificial data\n",
    "    - threshold(float): the upper bound of the missing rate\n",
    "    - output_matrix (np array of float): artificial data with generated nan \n",
    "    '''\n",
    "    n,m = matrix.shape[0], matrix.shape[1]\n",
    "    \n",
    "    p = np.random.uniform(0,threshold, n)\n",
    "    for i in range(n):\n",
    "        if p[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            ## Each of entry follows Bernoulli Distribution, so the entire row follows Binormial Distribution \n",
    "            ## Generate the number of missing data for user i \n",
    "            miss_num = np.random.binomial(m, p[i], 1)[0]\n",
    "            index = random.sample(range(m), miss_num)\n",
    "            matrix[i, index] = np.nan\n",
    "    return matrix\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_test = 0.8\n",
    "threhold_train = 0.1\n",
    "random.seed(30)\n",
    "test_matrix2  = data_generation(test_matrix2, threshold_test)\n",
    "train_matrix2 = data_generation(train_matrix2, threhold_train)\n",
    "# np.sum(np.isnan(test_matrix), axis = 1)\n",
    "# np.sum(np.isnan(train_matrix2), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\Omega_{x,y}$ be the set of items where both user $x$ and $y$ rated. $r_{x,i}$ denote rating for user $i$ on item $i$. \n",
    "\n",
    "Then \n",
    "$$\n",
    "\\operatorname{similarity}(x, y)=\\cos (\\vec{x}, \\vec{y})=\\frac{\\vec{x} \\cdot \\vec{y}}{\\|\\vec{x}\\| \\times\\|\\vec{y}\\|}=\\frac{\\sum_{i \\in \\Omega_{x y}} r_{x, i} r_{y, i}}{\\sqrt{\\sum_{i \\in \\Omega_{x}} r_{x, i}^{2}} \\sqrt{\\sum_{i \\in \\Omega_{y}} r_{y, i}^{2}}}\n",
    "$$\n",
    "\n",
    "\n",
    "### Some Problems:\n",
    "\n",
    "* Based on the formular, the rating vectors would be highly sparse, and only the rating in the set $\\Omega_{x,y}$ would be taken into our calculation. \n",
    "\n",
    "\n",
    "### Solution:\n",
    "\n",
    "\n",
    "There is a trick for calculating the cosine similarity between the sparse vector $A$ and $B$ is to <strong>assign 0 </strong>to the ```nan``` term.\n",
    "\n",
    "\n",
    "For example, array $A$  = array([  1.,   4.,   2.,  nan,   3.]), $B$ = array([ nan,  nan,   2.,   4.,   1.]).\n",
    "\n",
    "The dot product $A \\cdot B = (1 \\cdot nan) + (4 \\cdot nan) + (2 \\cdot 2) + (nan \\cdot 4) + (3 \\cdot 1)$. We only care about the $A_{i}$ and $B_{i}$ that are <strong>both not </strong> ```nan```.\n",
    "\n",
    "\n",
    "Therefore, we ignore all of the ```nan``` terms and only keep $(2 \\cdot 2) + (3 \\cdot 1) = 7$\n",
    "\n",
    "\n",
    "Since $A$ and $B$ can be any arbitrary vector, $\\left\\Vert{A}\\right\\Vert$ or $\\left\\Vert{B}\\right\\Vert$ would be the same case. $\\left\\Vert{A}\\right\\Vert= \\sqrt{A^{T} A}$, and the rest derivation would be the same. \n",
    "\n",
    "\n",
    "#### Before change: \n",
    "\n",
    "\n",
    "    - array([[        nan,  0.85219322,  0.03639481, ...,         nan,\n",
    "            -0.53096698,         nan],\n",
    "           [-0.95952211,  0.19562883,         nan, ..., -0.57070051,\n",
    "                nan,         nan],\n",
    "           [        nan,  0.53597783,         nan, ..., -0.87058322,\n",
    "               -0.14354887,  0.77974504],\n",
    "           ...,\n",
    "           [ 0.34881448,         nan, -0.4747643 , ...,         nan,\n",
    "             0.26291857,  0.74074827],\n",
    "           [        nan, -1.49807325, -0.36615501, ..., -0.05927307,\n",
    "                    nan,  0.66986875],\n",
    "           [        nan,         nan,  1.31932065, ...,  0.09099651,\n",
    "                    nan,         nan]])\n",
    "\n",
    "\n",
    "\n",
    "#### After change: \n",
    "\n",
    "\n",
    "    - array([[ 0.        ,  0.85219322,  0.03639481, ...,  0.        ,\n",
    "        -0.53096698,  0.        ],\n",
    "       [-0.95952211,  0.19562883,  0.        , ..., -0.57070051,\n",
    "         0.        ,  0.        ],\n",
    "       [ 0.        ,  0.53597783,  0.        , ..., -0.87058322,\n",
    "        -0.14354887,  0.77974504],\n",
    "       ...,\n",
    "       [ 0.34881448,  0.        , -0.4747643 , ...,  0.        ,\n",
    "         0.26291857,  0.74074827],\n",
    "       [ 0.        , -1.49807325, -0.36615501, ..., -0.05927307,\n",
    "         0.        ,  0.66986875],\n",
    "       [ 0.        ,  0.        ,  1.31932065, ...,  0.09099651,\n",
    "         0.        ,  0.        ]])\n",
    "\n",
    "\n",
    "\n",
    "Therefore, our recommend algorithm becomes very simple: \n",
    "   \n",
    "   - 1. Find ```nan``` term position and convert to 0\n",
    "   \n",
    "   \n",
    "   - 2. Choose an appropriate similarity metric and finish recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(train_matrix, test_matrix, k, metric):\n",
    "    \n",
    "    train_matrix = np.where(np.isnan(train_matrix),0,train_matrix)\n",
    "    test_matrix = np.where(np.isnan(test_matrix),0,test_matrix)\n",
    "    if metric == 'cosine':\n",
    "        return knn_cosine2(train_matrix, test_matrix, k)\n",
    "    elif metric == 'euclidean':\n",
    "        return knn_euclidean2(train_matrix, test_matrix, k)   \n",
    "    elif metric == 'Peason':\n",
    "        return Pearson_correlation2(train_matrix, test_matrix, k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([367, 617, 459, 558, 126]),\n",
       "  array([0.26883845, 0.26793302, 0.25842686, 0.25287088, 0.23756672])],\n",
       " 1: [array([299, 414, 125, 678, 486]),\n",
       "  array([0.32967686, 0.32850284, 0.30071541, 0.30016331, 0.28440624])],\n",
       " 2: [array([514, 605, 469, 877, 555]),\n",
       "  array([0.28153569, 0.27967002, 0.27234188, 0.2671912 , 0.25601659])],\n",
       " 3: [array([580, 245, 412, 348, 138]),\n",
       "  array([0.31794885, 0.25779714, 0.23483914, 0.23073941, 0.22835541])],\n",
       " 4: [array([637, 175, 307, 233, 567]),\n",
       "  array([0.32013892, 0.31773191, 0.26806747, 0.25999116, 0.25699336])],\n",
       " 5: [array([ 10, 207, 751, 942, 545]),\n",
       "  array([0.3277439 , 0.28022501, 0.27538722, 0.27115732, 0.27038886])],\n",
       " 6: [array([137, 445, 636, 144, 884]),\n",
       "  array([0.2916728 , 0.2914072 , 0.27994746, 0.25487281, 0.24495041])],\n",
       " 7: [array([  9, 465, 300, 711, 419]),\n",
       "  array([0.31335293, 0.30607488, 0.29928262, 0.29793504, 0.26106972])],\n",
       " 8: [array([ 44, 852, 583, 950, 643]),\n",
       "  array([0.39063421, 0.36559047, 0.36054409, 0.27604022, 0.2701158 ])],\n",
       " 9: [array([ 34, 499,  37, 228, 819]),\n",
       "  array([0.31647415, 0.28414801, 0.28304294, 0.26340541, 0.26053084])],\n",
       " 10: [array([488, 567, 548, 873, 999]),\n",
       "  array([0.31276402, 0.27860659, 0.27728463, 0.27071067, 0.25526975])],\n",
       " 11: [array([417, 900, 556, 906, 394]),\n",
       "  array([0.26706547, 0.25344033, 0.251477  , 0.2481564 , 0.23690828])],\n",
       " 12: [array([127, 435, 893, 332, 901]),\n",
       "  array([0.33524441, 0.33203286, 0.32227502, 0.27018169, 0.26732318])],\n",
       " 13: [array([346, 191, 752, 160, 474]),\n",
       "  array([0.28898346, 0.27216101, 0.26159366, 0.24185103, 0.24023349])],\n",
       " 14: [array([613, 932, 744, 709, 206]),\n",
       "  array([0.33894659, 0.31860977, 0.2994941 , 0.25401002, 0.24812947])],\n",
       " 15: [array([848, 553, 353, 885, 491]),\n",
       "  array([0.32378376, 0.3155907 , 0.31101181, 0.26650786, 0.25128155])],\n",
       " 16: [array([461, 816, 407,  86, 897]),\n",
       "  array([0.3253547 , 0.32195609, 0.28368345, 0.26663636, 0.26468265])],\n",
       " 17: [array([570, 603, 741, 900, 141]),\n",
       "  array([0.29124745, 0.28294276, 0.27270663, 0.26910736, 0.26755111])],\n",
       " 18: [array([959, 631, 633, 456, 286]),\n",
       "  array([0.28354204, 0.26937439, 0.26877037, 0.26254165, 0.26250611])],\n",
       " 19: [array([584, 900,   1,  96, 816]),\n",
       "  array([0.30208526, 0.28580034, 0.26452987, 0.25520373, 0.25304197])],\n",
       " 20: [array([306, 148, 398, 657, 634]),\n",
       "  array([0.30059666, 0.30014937, 0.29899743, 0.26823798, 0.26009101])],\n",
       " 21: [array([340, 195, 594, 778, 897]),\n",
       "  array([0.32355418, 0.30094433, 0.28538726, 0.27206478, 0.26433461])],\n",
       " 22: [array([ 63, 817, 961, 872, 562]),\n",
       "  array([0.34777386, 0.27993726, 0.27703308, 0.27463865, 0.26678211])],\n",
       " 23: [array([358, 203, 550, 129, 554]),\n",
       "  array([0.35130477, 0.28001184, 0.27390168, 0.25576452, 0.24243191])],\n",
       " 24: [array([443,  55,  13, 850,  59]),\n",
       "  array([0.30772021, 0.26080194, 0.26053629, 0.25864218, 0.24571393])],\n",
       " 25: [array([ 46, 579, 284, 873, 933]),\n",
       "  array([0.2756141 , 0.26095587, 0.25684344, 0.24669295, 0.23976379])],\n",
       " 26: [array([638, 797, 964,  51, 544]),\n",
       "  array([0.27774191, 0.27462986, 0.26996505, 0.26759647, 0.25820867])],\n",
       " 27: [array([974, 739, 726, 977,  92]),\n",
       "  array([0.36293798, 0.32431969, 0.30096401, 0.30075025, 0.29471776])],\n",
       " 28: [array([993, 252, 687, 406, 100]),\n",
       "  array([0.31825521, 0.2977792 , 0.29158724, 0.28615469, 0.25716686])],\n",
       " 29: [array([385, 584, 710, 282, 878]),\n",
       "  array([0.32772944, 0.3188434 , 0.29190425, 0.26687354, 0.25816282])],\n",
       " 30: [array([179, 786, 116, 207, 804]),\n",
       "  array([0.31627849, 0.29998999, 0.29424307, 0.26978256, 0.25244945])],\n",
       " 31: [array([ 39, 114, 343,  93, 262]),\n",
       "  array([0.29769283, 0.25535106, 0.25217284, 0.25049569, 0.25022224])],\n",
       " 32: [array([991,  27,   7, 325, 750]),\n",
       "  array([0.33956253, 0.33387927, 0.28178367, 0.26716656, 0.25444081])],\n",
       " 33: [array([949, 390, 270, 296, 913]),\n",
       "  array([0.32297031, 0.31098916, 0.29593684, 0.28607528, 0.26939343])],\n",
       " 34: [array([896, 535, 530, 202, 475]),\n",
       "  array([0.31580817, 0.29800404, 0.2897756 , 0.28499249, 0.2783828 ])],\n",
       " 35: [array([146, 381,  88, 605, 882]),\n",
       "  array([0.29540079, 0.28483901, 0.27758792, 0.26554893, 0.26257325])],\n",
       " 36: [array([685, 516,  12, 382, 503]),\n",
       "  array([0.31210698, 0.27681408, 0.27092775, 0.26292597, 0.24071933])],\n",
       " 37: [array([546, 625, 686, 628, 222]),\n",
       "  array([0.3045117 , 0.288105  , 0.27833318, 0.25807551, 0.25441612])],\n",
       " 38: [array([498, 173, 908,   3, 494]),\n",
       "  array([0.31091898, 0.30040145, 0.28484623, 0.26063331, 0.26023634])],\n",
       " 39: [array([711, 906, 264,  60, 454]),\n",
       "  array([0.3025041 , 0.29462586, 0.29428809, 0.251745  , 0.23966197])]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_matrix  = recommend(train_matrix2, test_matrix2, k = 5, metric = 'cosine')\n",
    "recommend_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction \n",
    "\n",
    "\n",
    "The prediction $P_{u, i }$ is given by \n",
    "$$\n",
    "P_{u,i}=\\frac{\\sum_{v}\\left(r_{v, i} \\cdot s_{u, v}\\right)}{\\sum_{v} s_{u, v}}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $P_{u,i}$ is the prediction of an item\n",
    "* $R_{v,i}$ is the rating given by a user $v$ to a movie $i$\n",
    "* $S_{u,v}$ is the similarity between users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Algorithm Peusudocode: \n",
    "\n",
    "- For each user in test_matrix: \n",
    "\n",
    "    - Find the most similar k ones and the corrsponding similarity between these two. (recommend matrix)\n",
    "    \n",
    "        - For each similiar user:\n",
    "    \n",
    "             - Find out the correspoding rating (training matrix)\n",
    "               \n",
    "             - Calculate $r_{v, i} \\cdot s_{u, v}$ \n",
    "        \n",
    "        - Normalize the score by the total similarity. \n",
    " \n",
    "        - Assign the normalized score to test user $i$\n",
    "\n",
    "- Finish prediction\n",
    "            \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(recommend_matrix, test_matrix, train_matrix):\n",
    "    predict_matrix = test_matrix.copy()\n",
    "    train_matrix = np.where(np.isnan(train_matrix),0,train_matrix)\n",
    "    for i in range(len(predict_matrix)):\n",
    "        id_s, cos = recommend_matrix[i][0], recommend_matrix[i][1]\n",
    "        score = 0\n",
    "        normalization = cos.sum()\n",
    "        for j in range(len(id_s)):\n",
    "            score += train_matrix[id_s[j]] * cos[j]\n",
    "        predict_matrix[i] = score/normalization\n",
    "    return predict_matrix\n",
    "\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31845256,  0.6785868 , -0.10221802, ..., -0.60886855,\n",
       "         0.12854086,  0.18045503],\n",
       "       [-1.43772708,  0.29922262,  0.66382105, ..., -0.04111721,\n",
       "        -0.61205164,  0.07936011],\n",
       "       [-0.2482317 , -0.39489954, -0.27574779, ...,  0.0900043 ,\n",
       "         0.28068771, -0.51815233],\n",
       "       ...,\n",
       "       [-0.53848214,  0.14769261,  0.03509299, ..., -0.99993866,\n",
       "        -0.147392  , -0.50592911],\n",
       "       [ 0.57478965, -0.35245785, -0.031045  , ..., -0.49016977,\n",
       "        -0.14229614,  0.32701247],\n",
       "       [ 0.78153718, -0.35431667, -0.39051795, ...,  0.61615279,\n",
       "        -0.50229709, -0.05609895]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict(recommend_matrix, test_matrix2, train_matrix2)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (not sure)\n",
    "\n",
    "\n",
    "The idea comes from the evaluate method of Matrix Factorization (ALS method)\n",
    "\n",
    "That is \n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\cdot \\sum_{i,j} \\left|M_{i j}-\\hat{M_{i j}}\\right|^{2}}\n",
    "$$\n",
    "\n",
    "where $(i,j) \\in \\Omega$ (observed).\n",
    "\n",
    "\n",
    "* $n$ is the number of the total predictions (~ nan).\n",
    "\n",
    "\n",
    "* $M_{i j}$ is the orginal test matrix. (highly sparse)\n",
    "\n",
    "\n",
    "* $\\hat{M_{i j}}$ is the predicted matrix. (no missing data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_matrix, predicted_matrix):\n",
    "    nan_pos = ~np.isnan(test_matrix)\n",
    "    num_nan = (~np.isnan(test_matrix)).sum()\n",
    "    RMSE = ((test_matrix[nan_pos] - predicted_matrix[nan_pos])** 2).sum() * (1/num_nan)\n",
    "    return RMSE ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814830214776919"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_matrix2, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Scale Approach\n",
    "\n",
    "\n",
    "* Rating scale approach: where a threshold is set and all the movies above that threshold are recommended.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_scale(train_matrix, test_matrix, threshold):\n",
    "    neightbor = {}\n",
    "    norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "    norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "    for i in range(len(test_matrix)):\n",
    "        cos = (train_matrix @ test_matrix[i].T) / (norm_train * norm_test[i])\n",
    "        cos_kept = []\n",
    "        cos_index = []\n",
    "        for j in range(len(cos)):\n",
    "            if cos[j] >= threshold:\n",
    "                cos_kept.append(cos[j])\n",
    "                cos_index.append(j)\n",
    "#       cos_kept = cos[cos >= threshold]\n",
    "\n",
    "        neightbor[i] = [cos_index,cos_kept]\n",
    "    return neightbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Scale Approach v.s. Top n Approach\n",
    "\n",
    "\n",
    "* 1. The user that the system recommend is very similar to that of by Top n approach.\n",
    "\n",
    "\n",
    "* 2. The users that recommended to our new users are guarantee to have high similiarity.       \n",
    "\n",
    "\n",
    "* 3. If the threshold that we set up is high, it would result in an empty list situation. That means there is no similar user to recommend. \n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[582, 659], [0.3303032828766637, 0.3716934831862149]],\n",
       " 1: [[637, 805], [0.30858770806948954, 0.31128586022737387]],\n",
       " 2: [[534, 875], [0.33250796350179196, 0.3459024555919765]],\n",
       " 3: [[197], [0.3030792478162777]],\n",
       " 4: [[577], [0.33339970171168576]],\n",
       " 5: [[632], [0.3204999067918686]],\n",
       " 6: [[437], [0.34040625359142007]],\n",
       " 7: [[630, 696], [0.30177549511805635, 0.31396681346384614]],\n",
       " 8: [[88], [0.33272808418871563]],\n",
       " 9: [[179, 778], [0.36229599631067844, 0.30534465564246677]],\n",
       " 10: [[267, 603], [0.35413512998785435, 0.3073897875705601]],\n",
       " 11: [[239, 514, 680],\n",
       "  [0.33369753887100057, 0.31685539406905255, 0.3157191642402268]],\n",
       " 12: [[89, 761], [0.32654563366468997, 0.3404135494168592]],\n",
       " 13: [[374, 458, 609, 786, 833],\n",
       "  [0.3366271835375453,\n",
       "   0.3311494226585573,\n",
       "   0.3401700804120999,\n",
       "   0.3382897368679628,\n",
       "   0.3668158384927615]],\n",
       " 14: [[62], [0.3013480137149904]],\n",
       " 15: [[66, 132], [0.30864586659173976, 0.361744201993073]],\n",
       " 16: [[789], [0.3416252405743555]],\n",
       " 17: [[], []],\n",
       " 18: [[816], [0.3174132198578087]],\n",
       " 19: [[44], [0.30660918173868]],\n",
       " 20: [[481], [0.3063697710738018]],\n",
       " 21: [[269], [0.3602092714480387]],\n",
       " 22: [[34, 387], [0.3035185040809075, 0.3126685961915971]],\n",
       " 23: [[987], [0.3438514619358963]],\n",
       " 24: [[789], [0.3203491492589129]],\n",
       " 25: [[], []],\n",
       " 26: [[], []],\n",
       " 27: [[919], [0.375672986022149]],\n",
       " 28: [[254, 958], [0.3895665067221287, 0.32991431130204923]],\n",
       " 29: [[], []],\n",
       " 30: [[103, 602, 818],\n",
       "  [0.37144182855360125, 0.3247789221352622, 0.3422520200407894]],\n",
       " 31: [[221, 733, 902],\n",
       "  [0.3591835338842812, 0.3069112820731762, 0.3484110046972804]],\n",
       " 32: [[890], [0.332980509155444]],\n",
       " 33: [[79], [0.3358645204082557]],\n",
       " 34: [[280, 745, 985],\n",
       "  [0.3128909149884071, 0.3114353682239883, 0.3019598396611536]],\n",
       " 35: [[], []],\n",
       " 36: [[101, 738], [0.34059548453895766, 0.31926080308239385]],\n",
       " 37: [[231], [0.3014168738245902]],\n",
       " 38: [[339], [0.32309540062617603]],\n",
       " 39: [[], []]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "train_matrix3 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 1000)\n",
    "test_matrix3 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 40)\n",
    "scale = 0.3\n",
    "rec = rating_scale(train_matrix3, test_matrix3, scale)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([659, 582, 706]), array([0.37169348, 0.33030328, 0.27790668])],\n",
       " 1: [array([805, 637, 794]), array([0.31128586, 0.30858771, 0.27382839])],\n",
       " 2: [array([875, 534, 381]), array([0.34590246, 0.33250796, 0.29493481])],\n",
       " 3: [array([197, 351, 567]), array([0.30307925, 0.29291999, 0.28024302])],\n",
       " 4: [array([577,  42, 628]), array([0.3333997 , 0.29441229, 0.27804519])],\n",
       " 5: [array([632, 477, 495]), array([0.32049991, 0.27317848, 0.25993029])],\n",
       " 6: [array([437, 267, 762]), array([0.34040625, 0.29994601, 0.2665654 ])],\n",
       " 7: [array([696, 630, 421]), array([0.31396681, 0.3017755 , 0.26741943])],\n",
       " 8: [array([ 88, 863, 235]), array([0.33272808, 0.2924258 , 0.26720583])],\n",
       " 9: [array([179, 778, 441]), array([0.362296  , 0.30534466, 0.28849207])],\n",
       " 10: [array([267, 603, 803]), array([0.35413513, 0.30738979, 0.28416682])],\n",
       " 11: [array([239, 514, 680]), array([0.33369754, 0.31685539, 0.31571916])],\n",
       " 12: [array([761,  89, 798]), array([0.34041355, 0.32654563, 0.27633357])],\n",
       " 13: [array([833, 609, 786]), array([0.36681584, 0.34017008, 0.33828974])],\n",
       " 14: [array([ 62, 801, 399]), array([0.30134801, 0.29791478, 0.29575607])],\n",
       " 15: [array([132,  66, 795]), array([0.3617442 , 0.30864587, 0.29268579])],\n",
       " 16: [array([789, 997, 393]), array([0.34162524, 0.26886536, 0.26058095])],\n",
       " 17: [array([951, 562,  34]), array([0.28071774, 0.2747692 , 0.26853095])],\n",
       " 18: [array([816, 314, 854]), array([0.31741322, 0.291454  , 0.2896122 ])],\n",
       " 19: [array([ 44, 821, 202]), array([0.30660918, 0.29501452, 0.28618901])],\n",
       " 20: [array([481, 568, 357]), array([0.30636977, 0.27171812, 0.27132134])],\n",
       " 21: [array([269, 801, 940]), array([0.36020927, 0.29676031, 0.286458  ])],\n",
       " 22: [array([387,  34, 732]), array([0.3126686 , 0.3035185 , 0.26796404])],\n",
       " 23: [array([987, 307, 968]), array([0.34385146, 0.27777328, 0.27012565])],\n",
       " 24: [array([789, 603, 508]), array([0.32034915, 0.29705463, 0.29254077])],\n",
       " 25: [array([384, 932, 953]), array([0.27513177, 0.2750185 , 0.25838602])],\n",
       " 26: [array([715, 685, 426]), array([0.29337994, 0.25847335, 0.25534199])],\n",
       " 27: [array([919, 757, 175]), array([0.37567299, 0.26814146, 0.26702933])],\n",
       " 28: [array([254, 958, 918]), array([0.38956651, 0.32991431, 0.29125463])],\n",
       " 29: [array([596, 209, 497]), array([0.29421   , 0.27273132, 0.2710648 ])],\n",
       " 30: [array([103, 818, 602]), array([0.37144183, 0.34225202, 0.32477892])],\n",
       " 31: [array([221, 902, 733]), array([0.35918353, 0.348411  , 0.30691128])],\n",
       " 32: [array([890, 620, 163]), array([0.33298051, 0.27768933, 0.26131532])],\n",
       " 33: [array([ 79, 593,  62]), array([0.33586452, 0.2937226 , 0.29169721])],\n",
       " 34: [array([280, 745, 985]), array([0.31289091, 0.31143537, 0.30195984])],\n",
       " 35: [array([559, 216, 319]), array([0.29998711, 0.28633071, 0.28084229])],\n",
       " 36: [array([101, 738, 337]), array([0.34059548, 0.3192608 , 0.29680565])],\n",
       " 37: [array([231, 653, 739]), array([0.30141687, 0.27408683, 0.26594997])],\n",
       " 38: [array([339, 352, 583]), array([0.3230954 , 0.28372689, 0.27210234])],\n",
       " 39: [array([391, 973, 912]), array([0.29826001, 0.2749492 , 0.2703191 ])]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cosine2(train_matrix3, test_matrix3, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble to a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content_based_Recommendation():\n",
    "    \n",
    "    def __init__(self, train_matrix, test_matrix, metric):\n",
    "        \n",
    "        '''\n",
    "        - train_matrix (numpy.array of matrix): rating matrix for users in our dataset with a few missing term.\n",
    "        \n",
    "        - test_matrix (numpy.array of matrix): rating matrix for new users with many missing term. \n",
    "        \n",
    "        - metric (string): different recommendation approachs- \n",
    "                            {top_n approachs: [cosine, euclidean, Pearson correltion], \n",
    "                             scale_rating: [cosine]\n",
    "                            }\n",
    "                            \n",
    "        '''\n",
    "        \n",
    "        self.train_matrix = train_matrix\n",
    "        self.test_matrix = test_matrix\n",
    "        self.metric = metric\n",
    "        \n",
    "        \n",
    "    \n",
    "    def knn_cosine2(self, k):\n",
    "        neightbor = {}\n",
    "        norm_train = np.linalg.norm(self.train_matrix, axis = 1)\n",
    "        norm_test = np.linalg.norm(self.test_matrix, axis = 1)\n",
    "        for i in range(len(self.test_matrix)):\n",
    "            cos = (self.train_matrix @ self.test_matrix[i].T) / (norm_train * norm_test[i])\n",
    "            topk = np.argsort(-cos)[:k]\n",
    "            top_cos = -np.sort(-cos)[:k]\n",
    "            neightbor[i] = [topk,top_cos]\n",
    "        \n",
    "    \n",
    "    def knn_euclidean2(self, k):\n",
    "        neightbor = {}\n",
    "        for i in range(len(self.test_matrix)):\n",
    "            dist = np.linalg.norm((self.train_matrix - self.test_matrix[i].T), axis= 1)\n",
    "            topk = np.argsort(dist)[:k]\n",
    "            top_dist = -np.sort(-dist)[:k]\n",
    "            neightbor[i] = [topk,top_dist]\n",
    "            \n",
    "    \n",
    "    def Pearson_correlation2(self, k):\n",
    "        \n",
    "        train_matrix = self.train_matrix-np.mean(self.train_matrix, axis = 1).reshape(-1,1)\n",
    "        test_matrix = self.test_matrix-np.mean(self.test_matrix, axis = 1).reshape(-1,1)\n",
    "        neightbor = {}\n",
    "        norm_train = np.linalg.norm(train_matrix, axis = 1)\n",
    "        norm_test = np.linalg.norm(test_matrix, axis = 1)\n",
    "        for i in range(len(test_matrix)):\n",
    "            denominator = train_matrix @ test_matrix[i].T\n",
    "            numerator = norm_train * norm_test[i]\n",
    "            cos = denominator / numerator\n",
    "            topk = np.argsort(-cos)[:k]\n",
    "            top_cos = -np.sort(-cos)[:k]\n",
    "            neightbor[i] = [topk,top_cos]\n",
    "        \n",
    "    \n",
    "    def rating_scale(self, threshold):\n",
    "        neightbor = {}\n",
    "        norm_train = np.linalg.norm(self.train_matrix, axis = 1)\n",
    "        norm_test = np.linalg.norm(self.test_matrix, axis = 1)\n",
    "        for i in range(len(self.test_matrix)):\n",
    "            cos = (self.train_matrix @ self.test_matrix[i].T) / (norm_train * norm_test[i])\n",
    "            cos_kept = []\n",
    "            cos_index = []\n",
    "            for j in range(len(cos)):\n",
    "                if cos[j] >= threshold:\n",
    "                    cos_kept.append(cos[j])\n",
    "                    cos_index.append(j)\n",
    "            neightbor[i] = [cos_index,cos_kept]\n",
    "            \n",
    "    \n",
    "    def recommend(self, k):\n",
    "        \n",
    "        train_matrix = np.where(np.isnan(self.train_matrix),0,self.train_matrix)\n",
    "        test_matrix = np.where(np.isnan(self.test_matrix),0,self.test_matrix)\n",
    "        metric = self.metric\n",
    "        if metric == 'cosine':\n",
    "            self.recommend_matrix = knn_cosine2(train_matrix, test_matrix, k)\n",
    "        elif metric == 'euclidean':\n",
    "            self.recommend_matrix = knn_euclidean2(train_matrix, test_matrix, k)   \n",
    "        elif metric == 'Peason':\n",
    "            self.recommend_matrix = Pearson_correlation2(train_matrix, test_matrix, k)\n",
    "        elif metric == 'Scale_Rating':\n",
    "            self.recommend_matrix = Pearson_correlation2(train_matrix, test_matrix, k)\n",
    "        return self.recommend_matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_recommend(self,k):\n",
    "        self.recommend_matrix = recommend(self,k)\n",
    "        return self.recommend_matrix\n",
    "    \n",
    "    \n",
    "    def predict(self): \n",
    "        predict_matrix = self.test_matrix.copy()\n",
    "        train_matrix = np.where(np.isnan(self.train_matrix),0,self.train_matrix)\n",
    "        for i in range(len(predict_matrix)):\n",
    "            id_s, cos = self.recommend_matrix[i][0], self.recommend_matrix[i][1]\n",
    "            score = 0\n",
    "            normalization = cos.sum()\n",
    "            for j in range(len(id_s)):\n",
    "                score += train_matrix[id_s[j]] * cos[j]\n",
    "            predict_matrix[i] = score/normalization\n",
    "            \n",
    "        self.predict_matrix = predict_matrix\n",
    "        \n",
    "        return self.predict_matrix\n",
    "        \n",
    "    def get_predict_matrix(self):\n",
    "        self.predict_matrix = predict(self)\n",
    "        return self.predict_matrix\n",
    "    \n",
    "    def evaluate(self):\n",
    "        nan_pos = ~np.isnan(self.test_matrix)\n",
    "        num_nan = (~np.isnan(self.test_matrix)).sum()\n",
    "        RMSE = ((self.test_matrix[nan_pos] - self.predict_matrix[nan_pos])** 2).sum() * (1/num_nan)\n",
    "        return RMSE ** 0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Content_based_Recommendation(train_matrix3, test_matrix3, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05040326,  0.00468338,  0.12453094, ...,  1.43404583,\n",
       "        -0.5682777 , -0.01076042],\n",
       "       [-0.35203713, -0.09673517, -0.44227336, ...,  0.24596437,\n",
       "         0.61367342,  0.01281238],\n",
       "       [ 0.52109742, -0.10224799,  0.71282331, ..., -0.34219465,\n",
       "         0.15558906, -0.44953842],\n",
       "       ...,\n",
       "       [ 0.93559918, -0.13669867,  0.98377471, ..., -1.04650791,\n",
       "        -0.11718168, -0.32918681],\n",
       "       [-0.48585568, -0.52786607,  0.55069429, ...,  0.39327948,\n",
       "        -0.39115754,  0.05128761],\n",
       "       [ 0.03020775,  0.09453208, -0.49272892, ...,  0.78609346,\n",
       "         1.06114473, -0.45079808]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "model.recommend(k)\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240284217098169"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "\n",
    "### Cold Start Problem\n",
    "\n",
    "\n",
    "* New User Cold Start: when a new user is introduced in the dataset, there is no history of that user. It becomes harder to recommend products to that user.\n",
    "\n",
    "\n",
    "* Product Cold Start: when a new product comes out to the market.\n",
    "\n",
    "\n",
    "### Simulate Cold Start Problem in data generation process\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Set the upper bound for the parameter $p$ to be small for users matrix that is already in our dataset,  and to be extremely small $p = 0.01$ or $p = 0.05$ for new users matrix (test matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix4 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 1000)\n",
    "# test_matrix4 = np.random.multivariate_normal(np.zeros(100), np.identity(100), 40)\n",
    "threshold_test = 0.99\n",
    "threhold_train = 0.5\n",
    "test_matrix4  = data_generation(test_matrix3, threshold_test)\n",
    "train_matrix4 = data_generation(train_matrix3, threhold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "       1.90494915,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan, 0.48129226,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan, 0.26216648,        nan,        nan,\n",
       "              nan, 0.21366677,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan, 0.42607402,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan, 0.20855832,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "       0.04690772,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix4[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_matrix4)):\n",
    "    \n",
    "    if np.isnan(test_matrix4[i]).all():\n",
    "        print(i)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42528922,  0.39082204,  1.1384523 , ...,  0.08201892,\n",
       "         0.89072398, -0.05426291],\n",
       "       [ 0.18446023,  0.17822265,  0.14977251, ...,  0.22242213,\n",
       "        -0.17770872, -0.08597488],\n",
       "       [ 0.06804722,  0.        ,  0.02219324, ...,  0.06754473,\n",
       "        -0.13359436, -0.23451056],\n",
       "       ...,\n",
       "       [ 0.23352943, -0.04632696,  0.03410624, ..., -0.43128783,\n",
       "         0.39984582, -0.12592533],\n",
       "       [ 0.45600146,  0.17013748,  0.11948956, ..., -0.25256263,\n",
       "        -0.56509147, -0.14408346],\n",
       "       [-0.03659217, -0.23955437,  0.08318718, ...,  0.07719427,\n",
       "         0.04067955,  0.15962261]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Content_based_Recommendation(train_matrix4, test_matrix4, 'cosine')\n",
    "k = 5\n",
    "model2.recommend(k)\n",
    "model2.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704806602809465"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The manual featured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item no(left to right)</th>\n",
       "      <th>Male/Female</th>\n",
       "      <th>patten/ non-patten</th>\n",
       "      <th>blue/non-blue</th>\n",
       "      <th>black/non-black</th>\n",
       "      <th>green/non-green</th>\n",
       "      <th>color scale</th>\n",
       "      <th>collar</th>\n",
       "      <th>short sleeve/long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item no(left to right)  Male/Female  patten/ non-patten  blue/non-blue  \\\n",
       "0                       1            0                   1              1   \n",
       "1                       2            0                   0              1   \n",
       "2                       3            0                   1              0   \n",
       "3                       4            1                   0              1   \n",
       "4                       5            1                   1              0   \n",
       "\n",
       "   black/non-black  green/non-green  color scale  collar  short sleeve/long  \n",
       "0                0                0          0.5       1                  0  \n",
       "1                0                0          0.9       1                  0  \n",
       "2                1                0          1.0       1                  0  \n",
       "3                0                0          0.3       0                  0  \n",
       "4                0                1          0.5       0                  1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "manual_data = pd.read_csv('manual_data.csv')\n",
    "manual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
